{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuralk NICLClassifier: Housing Price Classification\n",
    "\n",
    "This notebook demonstrates Neuralk's **In-Context Learning (NICL)** classifier on a real-world housing dataset. The `NICLClassifier` follows the standard scikit-learn API, making it easy to integrate into existing ML pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Access\n",
    "\n",
    "To use the Neuralk Cloud API, you need an API key. Run the following command to get started:\n",
    "\n",
    "```bash\n",
    "neuralk login\n",
    "```\n",
    "\n",
    "This will display instructions and a link to create your account at: https://prediction.neuralk-ai.com/register\n",
    "\n",
    "Your API key will be generated upon registration. It looks like `nk_live_xxxxxxxxxxxx`.\n",
    "\n",
    "## Setting up your API key\n",
    "\n",
    "You can provide your API key in two ways:\n",
    "\n",
    "**Option 1: Environment variable (recommended)**\n",
    "\n",
    "```bash\n",
    "# Linux/macOS\n",
    "export NEURALK_API_KEY=nk_live_your_api_key_here\n",
    "\n",
    "# Windows\n",
    "set NEURALK_API_KEY=nk_live_your_api_key_here\n",
    "```\n",
    "\n",
    "**Option 2: Pass directly to the classifier**\n",
    "\n",
    "```python\n",
    "from neuralk import NICLClassifier\n",
    "clf = NICLClassifier(api_key=\"nk_live_your_api_key_here\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -q neuralk scikit-learn skrub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import skrub\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from neuralk import NICLClassifier, datasets\n",
    "\n",
    "skrub.set_config(use_table_report=False)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found unknown categories.*during transform\")\n",
    "\n",
    "API_KEY = os.environ.get(\"NEURALK_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test:  {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In-context learning models are pretrained.\n",
    "# The fit() call stores training data for context but does not perform traditional model fitting.\n",
    "classifier = NICLClassifier(api_key=API_KEY).fit(X_train, y_train)\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## 2. Real-World Dataset: Housing Price Classification\n",
    "\n",
    "Now we apply the classifier to a real dataset containing house descriptions and sale prices. The target is the sale price binned into categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.housing()\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print(f\"Classes: {y.nunique()}\")\n",
    "X.assign(Sale_Price=y).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preprocessing Pipeline\n",
    "\n",
    "The dataset contains mixed types (numeric, categorical, text). The `NICLClassifier` accepts only numeric input, so we build a preprocessing pipeline:\n",
    "\n",
    "1. **TableVectorizer** - encodes non-numeric columns\n",
    "2. **SquashingScaler** - normalizes feature scales\n",
    "3. **SimpleImputer** - handles missing values\n",
    "4. **PCA** - reduces dimensionality for optimal context efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nicl_pipeline = make_pipeline(\n",
    "    skrub.TableVectorizer(),\n",
    "    skrub.SquashingScaler(),\n",
    "    SimpleImputer(),\n",
    "    NICLClassifier(api_key=API_KEY),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(nicl_pipeline, X, y, error_score=\"raise\", scoring=\"accuracy\")\n",
    "\n",
    "print(f\"NICL Accuracy: {cv_results['test_score'].mean():.2%} (+/- {cv_results['test_score'].std():.2%})\")\n",
    "print(f\"Fold scores: {[f'{s:.2%}' for s in cv_results['test_score']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Baseline Comparison: Gradient Boosting\n",
    "\n",
    "For reference, we compare against `HistGradientBoostingClassifier` using the same preprocessing (without PCA, which degrades tree-based models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pipeline = make_pipeline(\n",
    "    skrub.TableVectorizer(),\n",
    "    skrub.SquashingScaler(),\n",
    "    SimpleImputer(),\n",
    "    HistGradientBoostingClassifier(),\n",
    ")\n",
    "\n",
    "cv_results_baseline = cross_validate(baseline_pipeline, X, y, error_score=\"raise\", scoring=\"accuracy\")\n",
    "\n",
    "print(f\"Gradient Boosting Accuracy: {cv_results_baseline['test_score'].mean():.2%} (+/- {cv_results_baseline['test_score'].std():.2%})\")\n",
    "print(f\"Fold scores: {[f'{s:.2%}' for s in cv_results_baseline['test_score']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "The `NICLClassifier` achieves competitive accuracy with minimal setup:\n",
    "\n",
    "- **No training required** - pretrained model uses context directly\n",
    "- **scikit-learn compatible** - integrates seamlessly with existing pipelines\n",
    "- **Handles large datasets** - automatic subsampling when needed\n",
    "\n",
    "For advanced usage including custom context selection, see the [Neuralk documentation](https://docs.neuralk-ai.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
